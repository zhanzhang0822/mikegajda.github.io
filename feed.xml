<?xml version="1.0" encoding="utf-8"?><?xml-stylesheet type="text/xml" href="/feed.xslt.xml"?><feed xmlns="http://www.w3.org/2005/Atom"><generator uri="http://jekyllrb.com" version="3.3.0">Jekyll</generator><link href="/feed.xml" rel="self" type="application/atom+xml" /><link href="/" rel="alternate" type="text/html" /><updated>2017-05-14T04:45:28+08:00</updated><id>//</id><title type="html">Zhang Zhan</title><entry><title type="html">Exposed &amp;amp; Interlaced – Exploring Motion in Analog and Digital (Ongoing)</title><link href="/2017/05/01/exposed-and-interlaced.html" rel="alternate" type="text/html" title="Exposed &amp; Interlaced – Exploring Motion in Analog and Digital (Ongoing)" /><published>2017-05-01T00:00:00+08:00</published><updated>2017-05-01T00:00:00+08:00</updated><id>/2017/05/01/exposed-and-interlaced</id><content type="html" xml:base="/2017/05/01/exposed-and-interlaced.html">&lt;h2 id=&quot;exposed--interlaced--exploring-motion-in-analog-and-digital-is-a-sequence-of-imaging-chronicling-a-dance-performance-into-10-different-fragments-the-viewer-will-be-able-to-view-each-fragment-as-a-long-exposure-film-print-as-a-representation-of-analog-means-and-an-interactive-lenticular-that-will-allow-the-viewer-to-see-a-short-video-clip-by-changing-their-perspective-as-a-representation-of-digital-means-the-fragments-will-be-displayed-sequentially-to-communicate-the-entire-dance-performance&quot;&gt;&lt;em&gt;Exposed &amp;amp; Interlaced – Exploring Motion in Analog and Digital&lt;/em&gt; is a sequence of imaging chronicling a dance performance into 10 different fragments. The viewer will be able to view each fragment as a long exposure film print, as a representation of analog means, and an interactive lenticular that will allow the viewer to see a short video clip by changing their perspective, as a representation of digital means. The fragments will be displayed sequentially to communicate the entire dance performance.&lt;/h2&gt;

&lt;iframe src=&quot;https://player.vimeo.com/video/215510021&quot; frameborder=&quot;0&quot; webkitallowfullscreen=&quot;&quot; mozallowfullscreen=&quot;&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;
&lt;p&gt;&lt;a href=&quot;https://vimeo.com/215510021&quot;&gt;Exposed &amp;amp; Interlaced - exploring motion in analog and digital&lt;/a&gt; from &lt;a href=&quot;https://vimeo.com/user36907083&quot;&gt;Zhang Zhan&lt;/a&gt; on &lt;a href=&quot;https://vimeo.com&quot;&gt;Vimeo&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Conceptual Development:&lt;/p&gt;

&lt;p&gt;This idea was formed with my own experiences here at NYU Shanghai and also when I studied abroad. I took the Intro to Film Photography class in NYU Prague with the great artist/Professor Bara Mrazkova. I loved every second of the class and also the time I got to spend in the darkroom, the unexpected surprises along with the special personality of the film, and the delicate nuance. I also took a class with Professor Moon last seamster at NYU Shanghai called Kinetic Interfaces, where I had the chance to experiment with Microsoft Kinect, a motion sensing device and the body movement data. For the final project of that class, I did a dance collaboration with my friend Ann. I was pretty amazed by how the human body was recognized and captured.&lt;/p&gt;

&lt;p&gt;I had this idea of doing human size photogram to show the human movement. According to Wikipedia, “a photogram is a photographic image made without a camera by placing objects directly onto the surface of a light-sensitive material such as photographic paper and then exposing it to light. The usual result is a negative shadow image that shows variations in tone that depends upon the transparency of the objects used. Areas of the paper that have received no light appear white; those exposed through transparent or semi-transparent objects appear grey” (https://en.wikipedia.org/wiki/Photogram). Then I found a photographic artist Floris Neusüss who did human size photograms (http://www.vonlintel.com/Floris-Neususs.html). I contacted the gallery inquiring about the process and materials and I heard back from them with the answers I needed. However, given the fact that this idea has a really strict requirement on the space, a darkroom with enough space with a big enough pool/bathtub for developing prints, and also the materials, customized size/unusual big size photo papers, which would potentially elevate the cost of the project by a fairly large amount as well as the time consumption. I decided to pivot it.&lt;/p&gt;

&lt;p&gt;Instead of analog media taking up the entire project, I though it would be a good idea to bring digital into the field. Kinect can sense and record body motion data in digital form, and film photography is analog way to record things. I started paying attention to the contrast and different between these two means. Although we live in an analog world, almost every single aspect has been heavily digitized. When you go to a concert, you see a wall of iPhones screen lit up; when you go to a museum, you see people with lenses capturing people striking poses with art works; people read pdfs; etc. Almost all the analog media have at least one or multiple replacements that feature convenience on user’s side when it comes to distribution, utilization and manipulation.&lt;/p&gt;

&lt;p&gt;Having dance as the as the content that shared by digital and analog approach of data recording, I started looking for media for presenting the data. AJ introduced lenticular and gifpop (https://gifpop.io) to me. Lenticular printing is a technology in which lenticular lenses (a technology that is also used for 3D displays) are used to produce printed images with an illusion of depth, or the ability to change or move as the image is viewed from different angles. I thought this would be a good way to present digital data which essentially is a short snippet of the dance piece and that data is in point-cloud form since digital recorded data can be easily modified and that directly shows how the Kinect device is sensing and selecting the samples, which is those dots where infrared light it emits lands. Same snippet of dance piece was also recorded on a long-exposed negative. After developing the negative, I printed it out with an enlarger onto a light sensitive photo paper. Each fragment of the dance piece has two presentations with one  being long-exposure film print and one being point-cloud lenticular sheet, and in total 10 fragments will be displayed sequentially to communicate the entire dance performance.&lt;/p&gt;

&lt;p&gt;The idea of this project is a culmination of my skill set as I am applying the film photography techniques I learned in Prague with the Kinect motion sensing skills I learned in IMA. A wholly original concept, this project dares to mix means of media that haven’t been mixed before and is an opportunity for me to contribute to the fields of work I have always admired in motion capture, film photography, and performance based art, while starting quality documentation in areas that have been ill documented, like lenticular printing.&lt;/p&gt;</content><category term="interactive-media" /><summary type="html">Exposed &amp;amp; Interlaced – Exploring Motion in Analog and Digital is a sequence of imaging chronicling a dance performance into 10 different fragments. The viewer will be able to view each fragment as a long exposure film print, as a representation of analog means, and an interactive lenticular that will allow the viewer to see a short video clip by changing their perspective, as a representation of digital means. The fragments will be displayed sequentially to communicate the entire dance performance.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="/exposed-and-interlaced-featured-image.jpg" /></entry><entry><title type="html">Swing</title><link href="/2017/03/23/swing.html" rel="alternate" type="text/html" title="Swing" /><published>2017-03-23T00:00:00+08:00</published><updated>2017-03-23T00:00:00+08:00</updated><id>/2017/03/23/swing</id><content type="html" xml:base="/2017/03/23/swing.html">&lt;h2 id=&quot;swing-is-a-new-music-interface-installation-featuring-a-swinging-lattern-with-elastics-it-soundifies-locations-acceleration-and-also-elasticity&quot;&gt;&lt;em&gt;Swing&lt;/em&gt; is a new music interface installation featuring a swinging lattern with elastics. It soundifies locations, acceleration, and also elasticity.&lt;/h2&gt;

&lt;iframe src=&quot;https://player.vimeo.com/video/210139899&quot; frameborder=&quot;0&quot; webkitallowfullscreen=&quot;&quot; mozallowfullscreen=&quot;&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;
&lt;p&gt;&lt;a href=&quot;https://vimeo.com/210139899&quot;&gt;Swing NIME final performance&lt;/a&gt; from &lt;a href=&quot;https://vimeo.com/user36907083&quot;&gt;Zhang Zhan&lt;/a&gt; on &lt;a href=&quot;https://vimeo.com&quot;&gt;Vimeo&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Filmed by Kinsa Durst&lt;/p&gt;

&lt;p&gt;Edited by Zhang Zhan&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Swing&lt;/em&gt; is my final project for NIME class at NYU Shanghai. It is an update of my previous project, Balls, based on p5.js and a mobile device that has the built-in accelerometer. I wanted to this it a step further by replacing p5.js with MAX/Msp as the sound generating platform and adding another physical object to amplify the movement triggering aspect of the project.&lt;/p&gt;

&lt;p&gt;In this project, a phone is placed inside of the lantern with diecut pattern. The lantern is hung by an elastic string. The built-in accelerometer sends current X, Y, Z value to MAX/Msp patch via Open Sound Control. The patch triggers three different sounds with three separate gate/threshold on each of X, Y, Z data. Through this piece, I am trying to soundify the relative movement of an object with the intervention of elastic.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/swing-1.jpg&quot; alt=&quot;_config.yml&quot; /&gt;
&lt;img src=&quot;/images/swing-2.jpg&quot; alt=&quot;_config.yml&quot; /&gt;
&lt;img src=&quot;/images/swing-3.jpg&quot; alt=&quot;_config.yml&quot; /&gt;
&lt;img src=&quot;/images/swing-4.jpg&quot; alt=&quot;_config.yml&quot; /&gt;
&lt;img src=&quot;/images/swing-5.jpg&quot; alt=&quot;_config.yml&quot; /&gt;
&lt;img src=&quot;/images/swing-6.jpg&quot; alt=&quot;_config.yml&quot; /&gt;
&lt;img src=&quot;/images/swing-7.jpg&quot; alt=&quot;_config.yml&quot; /&gt;
&lt;img src=&quot;/images/swing-8.jpg&quot; alt=&quot;_config.yml&quot; /&gt;
&lt;img src=&quot;/images/swing-9.jpg&quot; alt=&quot;_config.yml&quot; /&gt;
&lt;img src=&quot;/images/swing-10.jpg&quot; alt=&quot;_config.yml&quot; /&gt;
&lt;img src=&quot;/images/swing-11.jpg&quot; alt=&quot;_config.yml&quot; /&gt;
&lt;img src=&quot;/images/swing-12.jpg&quot; alt=&quot;_config.yml&quot; /&gt;&lt;/p&gt;</content><category term="interactive-media" /><summary type="html">Swing is a new music interface installation featuring a swinging lattern with elastics. It soundifies locations, acceleration, and also elasticity.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="/swing-featured-image.jpg" /></entry><entry><title type="html">Balls</title><link href="/2017/03/02/balls.html" rel="alternate" type="text/html" title="Balls" /><published>2017-03-02T00:00:00+08:00</published><updated>2017-03-02T00:00:00+08:00</updated><id>/2017/03/02/balls</id><content type="html" xml:base="/2017/03/02/balls.html">&lt;h2 id=&quot;balls-is-new-music-interface-based-on-p5-and-mobile-device-built-in-accelerometer-users-shake-their-phone-to-move-the-balls-and-when-two-of-them-collide-one-sound-clip-will-get-triggered&quot;&gt;&lt;em&gt;Balls&lt;/em&gt; is new music interface based on p5 and mobile device built-in accelerometer. Users shake their phone to move the balls and when two of them collide one sound clip will get triggered.&lt;/h2&gt;

&lt;p&gt;Project Demo: &lt;a href=&quot;/p5-balls/&quot; target=&quot;_blank&quot;&gt;Balls&lt;/a&gt; (for a better experience, please open the link on your mobile device)&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Balls&lt;/em&gt; is my project for NIME class at NYU Shanghai. Users open the project link on any mobile device with a built-in accelerometer, touch the screen once to activate sound, and shake the device. When two balls collide, short sound clips get triggered. There are three randomly generated balls so there are three differnt clips.&lt;/p&gt;

&lt;iframe src=&quot;https://player.vimeo.com/video/208103245&quot; frameborder=&quot;0&quot; webkitallowfullscreen=&quot;&quot; mozallowfullscreen=&quot;&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;
&lt;p&gt;&lt;a href=&quot;https://vimeo.com/208103245&quot;&gt;Balls&lt;/a&gt; from &lt;a href=&quot;https://vimeo.com/user36907083&quot;&gt;Zhang Zhan&lt;/a&gt; on &lt;a href=&quot;https://vimeo.com&quot;&gt;Vimeo&lt;/a&gt;.&lt;/p&gt;</content><category term="interactive-media" /><summary type="html">Balls is new music interface based on p5 and mobile device built-in accelerometer. Users shake their phone to move the balls and when two of them collide one sound clip will get triggered.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="/balls-featured-image.jpg" /></entry><entry><title type="html">NYU Shanghai Inaugural Commencement (Ongoing)</title><link href="/2017/02/01/nyu-shanghai-commencement.html" rel="alternate" type="text/html" title="NYU Shanghai Inaugural Commencement (Ongoing)" /><published>2017-02-01T00:00:00+08:00</published><updated>2017-02-01T00:00:00+08:00</updated><id>/2017/02/01/nyu-shanghai-commencement</id><content type="html" xml:base="/2017/02/01/nyu-shanghai-commencement.html">&lt;h2 id=&quot;various-signage-and-installation-design-for-nyu-shanghai-inaugural-commencement&quot;&gt;Various signage and installation design for NYU Shanghai Inaugural Commencement.&lt;/h2&gt;

&lt;p&gt;I am currently working in the design team for New York University Shanghai Commencement Committee for 88 上海, the inaugural commencement countdown event series.&lt;/p&gt;

&lt;p&gt;We kickoffed the countdown on March 2nd, 88 days prior to graduation and have 8 events from that time until the end. These events were designed to bring our inaugural class back together.&lt;/p&gt;

&lt;p&gt;I designed a brochure of commencement schedule and guest visiting check list. 88 上海 logo designed by Jingyi Sun. On-campus neon-light installations design for commencement day will come soon.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/nyu-shanghai-inaugural-commencement-countdown-1.jpg&quot; alt=&quot;_config.yml&quot; /&gt;
&lt;img src=&quot;/images/nyu-shanghai-inaugural-commencement-countdown-2.jpg&quot; alt=&quot;_config.yml&quot; /&gt;
&lt;img src=&quot;/images/nyu-shanghai-inaugural-commencement-countdown-3.jpg&quot; alt=&quot;_config.yml&quot; /&gt;&lt;/p&gt;</content><category term="design" /><summary type="html">Various signage and installation design for NYU Shanghai Inaugural Commencement.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="/nyu-shanghai-inaugural-commencement-countdown-featured-image.jpg" /></entry><entry><title type="html">Thirstea</title><link href="/2016/12/12/thirstea.html" rel="alternate" type="text/html" title="Thirstea" /><published>2016-12-12T00:00:00+08:00</published><updated>2016-12-12T00:00:00+08:00</updated><id>/2016/12/12/thirstea</id><content type="html" xml:base="/2016/12/12/thirstea.html">&lt;h2 id=&quot;thirstea-is-a-tea-plant-that-feeds-on-the-attention-it-gets-on-social-media-the-plant-gets-watered-with-new-followings-gained-thirstea-is-both-a-social-commentary-on-the-attention-seeking-behaviour-on-social-media-and-a-social-experiment-to-see-how-many-followers-it-can-get-and-how-long-the-tree-can-live-off-social-media-attention&quot;&gt;&lt;em&gt;Thirstea&lt;/em&gt; is a tea plant that feeds on the attention it gets on social media. The plant gets watered with new followings gained. &lt;em&gt;Thirstea&lt;/em&gt; is both a social commentary on the attention-seeking behaviour on social media and a social experiment to see how many followers it can get and how long the tree can live off social media attention.&lt;/h2&gt;

&lt;iframe src=&quot;https://player.vimeo.com/video/195745514&quot; frameborder=&quot;0&quot; webkitallowfullscreen=&quot;&quot; mozallowfullscreen=&quot;&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;
&lt;p&gt;&lt;a href=&quot;https://vimeo.com/195745514&quot;&gt;Thirstea&lt;/a&gt; from &lt;a href=&quot;https://vimeo.com/user36907083&quot;&gt;Zhang Zhan&lt;/a&gt; on &lt;a href=&quot;https://vimeo.com&quot;&gt;Vimeo&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Video filmed and edited by Zhang Zhan&lt;/p&gt;

&lt;p&gt;Project by Richard Lewei Huang and Zhang Zhan&lt;/p&gt;

&lt;p&gt;Music: Bon Iver - 8 (circle)&lt;/p&gt;

&lt;p&gt;The project is made up of a plant of tea tree and an irrigation system that is hooked to a Twitter bot and a webcam. The twitter bot will tweet about the growth of the plant every day with photos of the plant, and when the number of new followers gained that day exceeds 3 – we opted to give the plant water for every single follower it gets. The program checks for new followers every 10 minutes, and runs the motor for 1 minute for each follower gained. In this way the program can be more responsive to changes on social media.&lt;/p&gt;

&lt;p&gt;We purchased a second-hand HP desktop computer at a seedy location near the Baoshan Rd electronics market with 139 kuai (20 dollars). To implement the idea we program the arduino to communicate with whatever it connects to via serial. On the computer side, we opted to use Python for its versatility and its wealth of libraries that are ready-to-use. We used Twython to communicate with Twitter, PySerial to talk with the Arduino with serial.&lt;/p&gt;

&lt;p&gt;Python sketch here: &lt;a href=&quot;http://pastebin.com/81TD8zd8&quot; target=&quot;_blank&quot;&gt;http://pastebin.com/81TD8zd8&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;We used an Android phone kindly donated by luis m-n as a webcam. The phone, equipped with IP Webcam app, serves a livestream from its IP address on the WiFi network. We connected the computer onto the same WiFi so that both can communicate.&lt;/p&gt;

&lt;p&gt;We built a rectangle frame to be placed on the ground, and one arm was installed vertically at one of the four corners to support another horizontal arm with a drilled hole at the end so that water tube could fit the hole and water can drip from right above the tea tree plant.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/thirstea-1.jpg&quot; alt=&quot;_config.yml&quot; /&gt;
&lt;img src=&quot;/images/thirstea-2.jpg&quot; alt=&quot;_config.yml&quot; /&gt;
&lt;img src=&quot;/images/thirstea-3.jpg&quot; alt=&quot;_config.yml&quot; /&gt;
&lt;img src=&quot;/images/thirstea-4.jpg&quot; alt=&quot;_config.yml&quot; /&gt;
&lt;img src=&quot;/images/thirstea-5.jpg&quot; alt=&quot;_config.yml&quot; /&gt;
&lt;img src=&quot;/images/thirstea-6.jpg&quot; alt=&quot;_config.yml&quot; /&gt;
&lt;img src=&quot;/images/thirstea-7.jpg&quot; alt=&quot;_config.yml&quot; /&gt;
&lt;img src=&quot;/images/thirstea-8.jpg&quot; alt=&quot;_config.yml&quot; /&gt;
&lt;img src=&quot;/images/thirstea-9.jpg&quot; alt=&quot;_config.yml&quot; /&gt;
&lt;img src=&quot;/images/thirstea-10.jpg&quot; alt=&quot;_config.yml&quot; /&gt;
&lt;img src=&quot;/images/thirstea-11.jpg&quot; alt=&quot;_config.yml&quot; /&gt;&lt;/p&gt;</content><category term="interactive-media" /><summary type="html">Thirstea is a tea plant that feeds on the attention it gets on social media. The plant gets watered with new followings gained. Thirstea is both a social commentary on the attention-seeking behaviour on social media and a social experiment to see how many followers it can get and how long the tree can live off social media attention.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="/thirstea-featured-image.jpg" /></entry><entry><title type="html">Above The Sea</title><link href="/2016/12/12/above-the-sea.html" rel="alternate" type="text/html" title="Above The Sea" /><published>2016-12-12T00:00:00+08:00</published><updated>2016-12-12T00:00:00+08:00</updated><id>/2016/12/12/above-the-sea</id><content type="html" xml:base="/2016/12/12/above-the-sea.html">&lt;h2 id=&quot;above-the-sea-translates-weather-forecast-datasea-level-and-main-weather-condition-of-a-certain-city-into-notes-and-chords-and-visualizes-the-data-in-a-column-system-in-p5-after-being-laser-cut-onto-the-clear-acrylic-board-the-songs-about-the-sea-level-and-weather-above-the-sea-can-be-played-on-a-record-player&quot;&gt;&lt;em&gt;Above The Sea&lt;/em&gt; translates weather forecast data(sea level and main weather condition) of a certain city into notes and chords and visualizes the data in a column system in p5. After being laser cut onto the clear acrylic board, the songs about the sea level and weather above the sea can be played on a record player.&lt;/h2&gt;

&lt;p&gt;Project Demo: &lt;a href=&quot;/p5-above-the-sea/&quot; target=&quot;_blank&quot;&gt;Above The Sea – Shanghai&lt;/a&gt; (for a better experience, please open the link in Google Chrome)&lt;/p&gt;

&lt;iframe src=&quot;https://player.vimeo.com/video/195638313&quot; frameborder=&quot;0&quot; webkitallowfullscreen=&quot;&quot; mozallowfullscreen=&quot;&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;
&lt;p&gt;&lt;a href=&quot;https://vimeo.com/195638313&quot;&gt;Above The Sea&lt;/a&gt; from &lt;a href=&quot;https://vimeo.com/user36907083&quot;&gt;Zhang Zhan&lt;/a&gt; on &lt;a href=&quot;https://vimeo.com&quot;&gt;Vimeo&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Video filmed and edited by Zhang Zhan&lt;/p&gt;

&lt;p&gt;Music: Bon Iver - 666 ʇ&lt;/p&gt;

&lt;p&gt;This projects gets weather forecast data from the 5 day/3 hour forecast API from &lt;a href=&quot;http://openweathermap.org/api&quot; target=&quot;_blank&quot;&gt;OpenWeatherMap&lt;/a&gt;. Since the minimum unit of the data interval is 3 hours, the API gives me about 35-40 pairs of the sea level and main weather condition data. Each 3 hour interval represents one bar, and each bar has 8 beats of notes in membrane synth in one chord with a certain arrangement that represent main weather condition in that interval. There’s also a longer note created in FM synth representing the sea level. The API is live, which means it gets updated every 10 minutes(this interval is set in P5 so it can be changed easily).&lt;/p&gt;

&lt;p&gt;With my professor Luisa’s help, I decided to map 4 main weather conditions received from the weather forecast API with notes in 4 different chords.&lt;/p&gt;

&lt;p&gt;Clear – C major&lt;/p&gt;

&lt;p&gt;Clouds – C minor&lt;/p&gt;

&lt;p&gt;Rain – A minor&lt;/p&gt;

&lt;p&gt;Snow – B minor&lt;/p&gt;

&lt;p&gt;The sea level data aka the long note that lasts through one bar is mapped into a scale of C4, D4, E4, F4, G4, A4, B4, C5 note.&lt;/p&gt;

&lt;p&gt;In order to preserve the songs, I opted to include &lt;a href=&quot;http://instructables.com/id/Laser-Cut-Record/?ALLSTEPS&quot; target=&quot;_blank&quot;&gt;laser cut records&lt;/a&gt; as part of the project since the idea itself is really fascinating and you can play it back anytime you want. I needed to record the piece first and then run it through the python program and processing sketch provided by the instructables post. However, I had to make some modifications such as the size of the records, the radius of the most inner grove, rpm, maximum size of the pdf files(since one song’s groves on one pdf will be way too much to be imported into illustrator, so I had to split them into 9 pdfs and then import them so that no groves will be missing.) I bought a record player on Taobao–230kuai–the cheapest but legitimate one I could find. I then did testing with a random song in three settings suggested by the post–frequency 5000, speed 100, dpi 1200, and power 12, 20 and 24. It turns out that power 20 one sounds the best.&lt;/p&gt;

&lt;p&gt;Then I laser cut three music pieces I recorded on Dec 6 of three cities–New York, Prague, and Shanghai–where I lived since last year.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/above-the-sea-1.jpg&quot; alt=&quot;_config.yml&quot; /&gt;
&lt;img src=&quot;/images/above-the-sea-2.jpg&quot; alt=&quot;_config.yml&quot; /&gt;
&lt;img src=&quot;/images/above-the-sea-3.jpg&quot; alt=&quot;_config.yml&quot; /&gt;
&lt;img src=&quot;/images/above-the-sea-4.jpg&quot; alt=&quot;_config.yml&quot; /&gt;
&lt;img src=&quot;/images/above-the-sea-5.jpg&quot; alt=&quot;_config.yml&quot; /&gt;
&lt;img src=&quot;/images/above-the-sea-6.jpg&quot; alt=&quot;_config.yml&quot; /&gt;
&lt;img src=&quot;/images/above-the-sea-7.jpg&quot; alt=&quot;_config.yml&quot; /&gt;&lt;/p&gt;

&lt;p&gt;After the laser cut process was done, I washed those three records with water and soap to get rid of all the tiny dust from the cutting processing.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/above-the-sea-8.jpg&quot; alt=&quot;_config.yml&quot; /&gt;
&lt;img src=&quot;/images/above-the-sea-9.jpg&quot; alt=&quot;_config.yml&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Listen to the result in the video. :)&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/above-the-sea-10.jpg&quot; alt=&quot;_config.yml&quot; /&gt;
&lt;img src=&quot;/images/above-the-sea-11.jpg&quot; alt=&quot;_config.yml&quot; /&gt;
&lt;img src=&quot;/images/above-the-sea-12.jpg&quot; alt=&quot;_config.yml&quot; /&gt;&lt;/p&gt;</content><category term="interactive-media" /><summary type="html">Above The Sea translates weather forecast data(sea level and main weather condition) of a certain city into notes and chords and visualizes the data in a column system in p5. After being laser cut onto the clear acrylic board, the songs about the sea level and weather above the sea can be played on a record player.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="/above-the-sea-featured-image.jpg" /></entry><entry><title type="html">A Song Without Words</title><link href="/2016/12/12/a-song-without-words.html" rel="alternate" type="text/html" title="A Song Without Words" /><published>2016-12-12T00:00:00+08:00</published><updated>2016-12-12T00:00:00+08:00</updated><id>/2016/12/12/a-song-without-words</id><content type="html" xml:base="/2016/12/12/a-song-without-words.html">&lt;h2 id=&quot;a-song-without-words-is-an-interactive-dance-piece-using-kinect-with-projection-of-visuals-created-live-based-on-the-body-movement-sensed-by-kinect&quot;&gt;&lt;em&gt;A Song Without Words&lt;/em&gt; is an interactive dance piece using Kinect with projection of visuals created live based on the body movement sensed by Kinect.&lt;/h2&gt;

&lt;iframe src=&quot;https://player.vimeo.com/video/195400876&quot; frameborder=&quot;0&quot; webkitallowfullscreen=&quot;&quot; mozallowfullscreen=&quot;&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;
&lt;p&gt;&lt;a href=&quot;https://vimeo.com/195400876&quot;&gt;A Song Without Words&lt;/a&gt; from &lt;a href=&quot;https://vimeo.com/user36907083&quot;&gt;Zhang Zhan&lt;/a&gt; on &lt;a href=&quot;https://vimeo.com&quot;&gt;Vimeo&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Dancer and choreographer: Ann Yang&lt;/p&gt;

&lt;p&gt;Music: Sandy Lam - 无言歌&lt;/p&gt;

&lt;p&gt;Filmed by Jingyi Sun, Maggie Walsh and Zhang Zhan&lt;/p&gt;

&lt;p&gt;Edited by Zhang Zhan&lt;/p&gt;

&lt;p&gt;This dance piece is a visual response to the song, 无言歌, by Sandy Lam. My friend, Ann Yang, a talented dancer, choreographed this dance under my general guideline. There are four stages in the dance performance–birth, accumulation, explosion, and decay. Each stage is represented by different visual effects such as point cloud, particle explosion system, particle ring, and particles collapsing. The main point cloud figure is the live visual resemblance of the dancer, and the dancer also react to the visuals by modifying her dance routines based on what the visual is created by her previous movements and positions.&lt;/p&gt;

&lt;p&gt;Thanks to Prof. JH Moon for letting me use his Mac Pro, keyboard, track pad, his screen, and the speaker. The visuals are created in a processing sketch with a control panel. Visuals are sent to Arena with syphon, but the control panel is not sent to the Arena so that I can do live control including particle speed, color gradience, transition over the visuals. A Kinect is used to sense the depth and capture the shape of the object within the sensing range. The explosion and particles is attracted by the closest point within the sensing area.&lt;/p&gt;

&lt;p&gt;Special thanks to Prof. JH Moon, Jingyi Sun and Maggie Walsh.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/a-song-without-words-1.jpg&quot; alt=&quot;_config.yml&quot; /&gt;
&lt;img src=&quot;/images/a-song-without-words-2.jpg&quot; alt=&quot;_config.yml&quot; /&gt;
&lt;img src=&quot;/images/a-song-without-words-3.jpg&quot; alt=&quot;_config.yml&quot; /&gt;
&lt;img src=&quot;/images/a-song-without-words-4.jpg&quot; alt=&quot;_config.yml&quot; /&gt;
&lt;img src=&quot;/images/a-song-without-words-5.jpg&quot; alt=&quot;_config.yml&quot; /&gt;
&lt;img src=&quot;/images/a-song-without-words-6.jpg&quot; alt=&quot;_config.yml&quot; /&gt;
&lt;img src=&quot;/images/a-song-without-words-7.jpg&quot; alt=&quot;_config.yml&quot; /&gt;&lt;/p&gt;</content><category term="interactive-media" /><summary type="html">A Song Without Words is an interactive dance piece using Kinect with projection of visuals created live based on the body movement sensed by Kinect.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="/a-song-without-words-featured-image.jpg" /></entry><entry><title type="html">Shy Mirror</title><link href="/2016/12/05/shy-mirror.html" rel="alternate" type="text/html" title="Shy Mirror" /><published>2016-12-05T00:00:00+08:00</published><updated>2016-12-05T00:00:00+08:00</updated><id>/2016/12/05/shy-mirror</id><content type="html" xml:base="/2016/12/05/shy-mirror.html">&lt;h2 id=&quot;shy-mirror-is-an-interactive-installation-created-by-alexis-zerafa-xiran-yang-and-me-shy-mirror-is-a-mirror-that-gently-rotates-90-degrees-when-someone-is-in-front-of-it-therefore-the-participant-can-not-see-his-own-reflection-in-the-mirror&quot;&gt;&lt;em&gt;Shy Mirror&lt;/em&gt; is an interactive installation created by Alexis Zerafa, Xiran Yang and me. &lt;em&gt;Shy Mirror&lt;/em&gt; is a mirror that gently rotates 90 degrees when someone is in front of it, therefore the participant can not see his own reflection in the mirror.&lt;/h2&gt;

&lt;iframe src=&quot;https://player.vimeo.com/video/194319808&quot; frameborder=&quot;0&quot; webkitallowfullscreen=&quot;&quot; mozallowfullscreen=&quot;&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;
&lt;p&gt;&lt;a href=&quot;https://vimeo.com/194319808&quot;&gt;Shy Mirror&lt;/a&gt; from &lt;a href=&quot;https://vimeo.com/user36907083&quot;&gt;Zhang Zhan&lt;/a&gt; on &lt;a href=&quot;https://vimeo.com&quot;&gt;Vimeo&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Filmed by Alexis Zerafa, Xiran Yang and Zhang Zhan&lt;/p&gt;

&lt;p&gt;Edited by Alexis Zerafa&lt;/p&gt;

&lt;p&gt;This project focuses on the narcissistic behaviors shared by common human beings. We would like to raise the participant’s self-awareness of narcissism by angling the mirror that people tend to walk up to and where they look at themselves. This action disables them from looking at themselves in the mirror and, instead, participants are forced to look at the reflection of others in the room. We like this idea because not only is the concept persuasive and easy to convey, but also the physical object is simplistic and relevant to a broad audience.&lt;/p&gt;

&lt;p&gt;The interaction part of the project is as simple as the concept–an infrared range finder and a stepper motor are connected to an Arduino Uno (a micro controller). Once the reading of the infrared range finder is smaller than the threshold we set according to many rounds of testing, which means an object is detected within the searching range, the Arduino Uno will tell the attached stepper motor to rotate 90 degrees. Once the reading of the infrared becomes bigger than the threshold, it means no more objects can be detected within the searching range, so the mirror would reset to the initial position as the reverse process after given the command to do so from the Arduino Uno. Participants are not required to actively interact with any electronic components; they need only get closer to the mirror. We would like the action to happen instinctively with very limited guidance, and in this way, the result–rotation of the mirror– triggered by the action would enhance the overall experience since it is unpredictable and, therefore, surprising.&lt;/p&gt;

&lt;p&gt;A wood box frame(40x100cm) covered with white fabric functions as the base of the entire project, inside which the circuit hides. A thin but strong wood board drilled onto the fours legs of the wood box is the top of the box, and the stepper motor is placed in the center of the top with four screws drilled through the board and into the four mounting holes in the motor. Only the raft sticks out of the top of the box and the motor body is underneath the top hidden behind the white fabric.The mirror, a 2mm acrylic board(40x100cm) with a mirror-like reflective surface that has a wood frame in the back, is hanging from the top part of a bigger frame that stands on the box so that there is no weight resting on the raft. A small wood piece sticks out from the bottom of the mirror frame and touch nearly half of the raft. A paper clip and some clear tape are used to tie the raft and the small wood piece so they do not slip, and the stepper motor can rotate the mirror smoothly. The infrared range finder is installed on the top wood bar that is facing the participants.&lt;/p&gt;

&lt;p&gt;The project is truly portable and easily reassembled due to the use of screws and lumber. It needs one socket nearby to power the circuit. We placed the project in a way that it was facing a white wall. Therefore the space in front of the range finder could be less crowded with a more still and pure background, which would definitely maintain the performance of the sensor at a good level. Even though the infrared range finder works well with normal room light, the room where &lt;em&gt;Shy Mirror&lt;/em&gt; is exhibited should have as little bright sunlight as possible since sunlight would decrease the accuracy of the range finder.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/shy-mirror-1.jpg&quot; alt=&quot;_config.yml&quot; /&gt;
&lt;img src=&quot;/images/shy-mirror-2.jpg&quot; alt=&quot;_config.yml&quot; /&gt;
&lt;img src=&quot;/images/shy-mirror-3.jpg&quot; alt=&quot;_config.yml&quot; /&gt;
&lt;img src=&quot;/images/shy-mirror-4.jpg&quot; alt=&quot;_config.yml&quot; /&gt;
&lt;img src=&quot;/images/shy-mirror-5.jpg&quot; alt=&quot;_config.yml&quot; /&gt;
&lt;img src=&quot;/images/shy-mirror-6.jpg&quot; alt=&quot;_config.yml&quot; /&gt;
&lt;img src=&quot;/images/shy-mirror-7.jpg&quot; alt=&quot;_config.yml&quot; /&gt;
&lt;img src=&quot;/images/shy-mirror-8.jpg&quot; alt=&quot;_config.yml&quot; /&gt;
&lt;img src=&quot;/images/shy-mirror-9.jpg&quot; alt=&quot;_config.yml&quot; /&gt;
&lt;img src=&quot;/images/shy-mirror-10.jpg&quot; alt=&quot;_config.yml&quot; /&gt;
&lt;img src=&quot;/images/shy-mirror-11.jpg&quot; alt=&quot;_config.yml&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Photo credits: Xiran Yang
&lt;img src=&quot;/images/shy-mirror-12.jpg&quot; alt=&quot;_config.yml&quot; /&gt;
&lt;img src=&quot;/images/shy-mirror-13.jpg&quot; alt=&quot;_config.yml&quot; /&gt;
&lt;img src=&quot;/images/shy-mirror-14.jpg&quot; alt=&quot;_config.yml&quot; /&gt;
&lt;img src=&quot;/images/shy-mirror-15.jpg&quot; alt=&quot;_config.yml&quot; /&gt;&lt;/p&gt;</content><category term="interactive-media" /><summary type="html">Shy Mirror is an interactive installation created by Alexis Zerafa, Xiran Yang and me. Shy Mirror is a mirror that gently rotates 90 degrees when someone is in front of it, therefore the participant can not see his own reflection in the mirror.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="/shy-mirror-featured-image.jpg" /></entry><entry><title type="html">Little Brothers Entertainment Brochure</title><link href="/2016/10/20/little-brothers-entertainment-brochure.html" rel="alternate" type="text/html" title="Little Brothers Entertainment Brochure" /><published>2016-10-20T00:00:00+08:00</published><updated>2016-10-20T00:00:00+08:00</updated><id>/2016/10/20/little-brothers-entertainment-brochure</id><content type="html" xml:base="/2016/10/20/little-brothers-entertainment-brochure.html">&lt;h2 id=&quot;company-overview-brochure-design-for-little-brothers-entertainment-based-in-shanghai&quot;&gt;Company overview brochure design for Little Brothers Entertainment based in Shanghai.&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/images/little-brothers-entertainment-brochure-1.jpg&quot; alt=&quot;_config.yml&quot; /&gt;
&lt;img src=&quot;/images/little-brothers-entertainment-brochure-2.jpg&quot; alt=&quot;_config.yml&quot; /&gt;
&lt;img src=&quot;/images/little-brothers-entertainment-brochure-3.jpg&quot; alt=&quot;_config.yml&quot; /&gt;
&lt;img src=&quot;/images/little-brothers-entertainment-brochure-4.jpg&quot; alt=&quot;_config.yml&quot; /&gt;
&lt;img src=&quot;/images/little-brothers-entertainment-brochure-5.jpg&quot; alt=&quot;_config.yml&quot; /&gt;
&lt;img src=&quot;/images/little-brothers-entertainment-brochure-6.jpg&quot; alt=&quot;_config.yml&quot; /&gt;
&lt;img src=&quot;/images/little-brothers-entertainment-brochure-7.jpg&quot; alt=&quot;_config.yml&quot; /&gt;
&lt;img src=&quot;/images/little-brothers-entertainment-brochure-8.jpg&quot; alt=&quot;_config.yml&quot; /&gt;
&lt;img src=&quot;/images/little-brothers-entertainment-brochure-9.jpg&quot; alt=&quot;_config.yml&quot; /&gt;
&lt;img src=&quot;/images/little-brothers-entertainment-brochure-10.jpg&quot; alt=&quot;_config.yml&quot; /&gt;
&lt;img src=&quot;/images/little-brothers-entertainment-brochure-11.jpg&quot; alt=&quot;_config.yml&quot; /&gt;
&lt;img src=&quot;/images/little-brothers-entertainment-brochure-12.jpg&quot; alt=&quot;_config.yml&quot; /&gt;
&lt;img src=&quot;/images/little-brothers-entertainment-brochure-13.jpg&quot; alt=&quot;_config.yml&quot; /&gt;
&lt;img src=&quot;/images/little-brothers-entertainment-brochure-14.jpg&quot; alt=&quot;_config.yml&quot; /&gt;
&lt;img src=&quot;/images/little-brothers-entertainment-brochure-15.jpg&quot; alt=&quot;_config.yml&quot; /&gt;
&lt;img src=&quot;/images/little-brothers-entertainment-brochure-16.jpg&quot; alt=&quot;_config.yml&quot; /&gt;
&lt;img src=&quot;/images/little-brothers-entertainment-brochure-17.jpg&quot; alt=&quot;_config.yml&quot; /&gt;&lt;/p&gt;</content><category term="design" /><summary type="html">Company overview brochure design for Little Brothers Entertainment based in Shanghai.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="/little-brothers-entertainment-brochure-featured-image.jpg" /></entry><entry><title type="html">Pop &amp;amp; Poem Typewriter</title><link href="/2016/10/04/pop-and-poem-typewriter.html" rel="alternate" type="text/html" title="Pop &amp; Poem Typewriter" /><published>2016-10-04T00:00:00+08:00</published><updated>2016-10-04T00:00:00+08:00</updated><id>/2016/10/04/pop-and-poem-typewriter</id><content type="html" xml:base="/2016/10/04/pop-and-poem-typewriter.html">&lt;h2 id=&quot;pop--poem-typewriter-is-an-interactive-web-based-project-where-users-type-a-poem-while-triggering-sound-clips-from-various-pop-songs-that-read-out-whatever-letters-users-are-typing&quot;&gt;&lt;em&gt;Pop &amp;amp; Poem Typewriter&lt;/em&gt; is an interactive web-based project where users type a poem while triggering sound clips from various pop songs that read out whatever letters users are typing.&lt;/h2&gt;

&lt;p&gt;Project Demo: &lt;a href=&quot;/p5-pop-and-poem-typewriter/&quot; target=&quot;_blank&quot;&gt;Pop &amp;amp; Poem Typewriter&lt;/a&gt; (for a better experience, please open the link in Google Chrome)&lt;/p&gt;

&lt;iframe src=&quot;https://player.vimeo.com/video/190374026&quot; frameborder=&quot;0&quot; webkitallowfullscreen=&quot;&quot; mozallowfullscreen=&quot;&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;
&lt;p&gt;&lt;a href=&quot;https://vimeo.com/190374026&quot;&gt;Pop &amp;amp; Poem Typewriter&lt;/a&gt; from &lt;a href=&quot;https://vimeo.com/user36907083&quot;&gt;Zhang Zhan&lt;/a&gt; on &lt;a href=&quot;https://vimeo.com&quot;&gt;Vimeo&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Pop &amp;amp; Poem Typewriter is my midterm project for Code of Music class at NYU Shanghai. Each of the 40 Keys including A-Z(26), 0-9(10), Delete, Period, Comma, Space is linked to a small wav clip cut out from a pop song where the singer(s) spell out the letter or word. As you type a poem, a song made of those corresponding small clips will be triggered at the same time. I was looking to translate text into music to form the link between visual and aural via the contrast between letters in poem and pop music sound clips. To be honest, this project doesn’t have to involve poems, thus any text would trigger a piece of musical collage of short sound clips. I hope people could get a brand new experience of typing with the aural feedback that’s seldom happening when people type except for the monotone keyboard sound or the sounds of fingers hitting the buttons.&lt;/p&gt;

&lt;p&gt;Song list:&lt;/p&gt;

&lt;p&gt;A - The Jackson 5 - ABC&lt;/p&gt;

&lt;p&gt;B - The Black Eyed Peas - Imma Be&lt;/p&gt;

&lt;p&gt;C - Wiz Khalifa - See You Again ft. Charlie Puth&lt;/p&gt;

&lt;p&gt;D - Fergie - Fergalicious&lt;/p&gt;

&lt;p&gt;E - Macklemore &amp;amp; Ryan Lewis - Can’t Hold Us feat. Ray Dalton&lt;/p&gt;

&lt;p&gt;F - Noah And The Whale - L.I.F.E.G.O.E.S.O.N.&lt;/p&gt;

&lt;p&gt;G - Girls’ Generation(소녀시대) - Gee&lt;/p&gt;

&lt;p&gt;H - Jay-Z - Izzo (H.O.V.A.)&lt;/p&gt;

&lt;p&gt;I - Selena Gomez &amp;amp; The Scene - Love You Like A Love Song&lt;/p&gt;

&lt;p&gt;J - Jason Derulo - Don’t Wanna Go Home&lt;/p&gt;

&lt;p&gt;K - The Script - If You See Kay&lt;/p&gt;

&lt;p&gt;L - Madonna - Give Me All Your Luvin’ (Feat. M.I.A. and Nicki Minaj)&lt;/p&gt;

&lt;p&gt;M - Village People - YMCA&lt;/p&gt;

&lt;p&gt;N - Ke$ha - Dinosaur&lt;/p&gt;

&lt;p&gt;O - Nicki Minaj - Anaconda&lt;/p&gt;

&lt;p&gt;P - Aretha Franklin - Respect&lt;/p&gt;

&lt;p&gt;Q - 5 Seconds Of Summer - 18&lt;/p&gt;

&lt;p&gt;R - Paramore - The Only Exception&lt;/p&gt;

&lt;p&gt;S - Gwen Stefani - Hollaback Girl&lt;/p&gt;

&lt;p&gt;T - Justice - D.A.N.C.E.&lt;/p&gt;

&lt;p&gt;U - Katy Perry - Hot N Cold&lt;/p&gt;

&lt;p&gt;V - Nat King Cole - L-O-V-E&lt;/p&gt;

&lt;p&gt;W - Beyoncé - World Wide Woman&lt;/p&gt;

&lt;p&gt;X - deadmau5 ft. Gerard Way - Professional Griefers&lt;/p&gt;

&lt;p&gt;Y - MAGIC! - Rude&lt;/p&gt;

&lt;p&gt;Z - Spice Girls - Wannabe&lt;/p&gt;

&lt;p&gt;1 - Drake - One Dance (feat. Wizkid &amp;amp; Kyla)&lt;/p&gt;

&lt;p&gt;2 - Justin Bieber - Sorry&lt;/p&gt;

&lt;p&gt;3 - Britney Spears - 3&lt;/p&gt;

&lt;p&gt;4 - Feist - 1234&lt;/p&gt;

&lt;p&gt;5 - The Proclaimers - I’m Gonna Be (500 Miles)&lt;/p&gt;

&lt;p&gt;6 - Far East Movement - Like A G6 ft. The Cataracs, DEV&lt;/p&gt;

&lt;p&gt;7 - Lukas Graham - 7 Years&lt;/p&gt;

&lt;p&gt;8 - Lady Gaga - Monster&lt;/p&gt;

&lt;p&gt;9 - Lana Del Rey - Summertime Sadness&lt;/p&gt;

&lt;p&gt;0 - Eminem - Space Bound&lt;/p&gt;

&lt;p&gt;Delete - Maroon 5 - Unkiss Me&lt;/p&gt;

&lt;p&gt;Period - French Montana - Figure it Out ft. Kanye West, Nas&lt;/p&gt;

&lt;p&gt;Comma - Coldplay - Every Teardrop Is a Waterfall&lt;/p&gt;

&lt;p&gt;Space - Taylor Swift - Blank Space&lt;/p&gt;</content><category term="interactive-media" /><summary type="html">Pop &amp;amp; Poem Typewriter is an interactive web-based project where users type a poem while triggering sound clips from various pop songs that read out whatever letters users are typing.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="/pop-and-poem-typewriter-featured-image.jpg" /></entry></feed>
